{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of Edits\n",
    "\n",
    "What percent of newcomers save a suggested edit?\n",
    "\n",
    "In this case, we'll use `mediawiki_history`, the processed version of the replicated databases, as our source of truth for edit data. We could also use `mediawiki_revision_tags_change` as we did in the Variant A/B analysis, but since we in this case have the former available to use, I prefer that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from wmfdata import hive, spark, mariadb\n",
    "from growth import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start timestamp of the Variant C/D experiment, which is when the edit tag bug fix went into place\n",
    "exp_start_ts = dt.datetime(2020, 10, 28, 18, 40, 2)\n",
    "\n",
    "## Ordered list of wikis that we'll be gathering data for\n",
    "## Note that we're excluding euwiki due to their small number of registrations\n",
    "wikis = ['cswiki', 'kowiki', 'viwiki', 'arwiki', 'ukwiki', 'huwiki', 'srwiki', 'hywiki',\n",
    "         'frwiki', 'fawiki', 'hewiki', 'ruwiki', 'plwiki', 'ptwiki', 'svwiki', 'trwiki']\n",
    "\n",
    "## The mediawiki_history snapshot we'll be working with\n",
    "wmf_snapshot = '2020-11'\n",
    "\n",
    "## The canonical user table that we'll join mediawiki_history with\n",
    "canonical_user_table = 'nettrom_growth.hp_variant_test2'\n",
    "\n",
    "## Where we write out the resulting dataset for further analysis\n",
    "edit_data_output_filename = 'datasets/variant-test-2-edit-data.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_data_query = '''\n",
    "WITH edits AS (\n",
    "    SELECT wiki_db, event_user_id AS user_id, SUM(1) AS num_article_edits,\n",
    "    SUM(IF(array_contains(revision_tags, \"newcomer task\"), 1, 0)) AS num_suggested_edits\n",
    "    FROM wmf.mediawiki_history\n",
    "    WHERE snapshot = \"{snapshot}\"\n",
    "    AND event_entity = \"revision\"\n",
    "    AND event_type = \"create\"\n",
    "    AND wiki_db IN ({wiki_list})\n",
    "    AND event_timestamp > \"{start_date}\"\n",
    "    -- only article edits\n",
    "    AND page_namespace = 0\n",
    "    -- within 24 hours of registration\n",
    "    AND unix_timestamp(event_timestamp) - unix_timestamp(event_user_creation_timestamp) < 86400\n",
    "    GROUP BY wiki_db, event_user_id\n",
    "),\n",
    "users AS (\n",
    "    SELECT wiki_db, user_id, user_registration, reg_on_mobile, hp_enabled, hp_variant\n",
    "    FROM {exp_user_table}\n",
    ")\n",
    "SELECT users.wiki_db, users.user_id, users.user_registration, reg_on_mobile, hp_enabled, hp_variant,\n",
    "    COALESCE(num_article_edits, 0) AS num_article_edits,\n",
    "    COALESCE(num_suggested_edits, 0) AS num_suggested_edits\n",
    "FROM users\n",
    "LEFT JOIN edits\n",
    "ON users.wiki_db = edits.wiki_db\n",
    "AND users.user_id = edits.user_id\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_edit_data = spark.run(\n",
    "    edit_data_query.format(\n",
    "        snapshot = wmf_snapshot,\n",
    "        wiki_list = ','.join(['\"{}\"'.format(w) for w in wikis]),\n",
    "        start_date = exp_start_ts.date().isoformat(),\n",
    "        exp_user_table = canonical_user_table\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67599"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_users_edit_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_edit_data.loc[all_users_edit_data['num_article_edits'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_edit_data.loc[all_users_edit_data['num_suggested_edits'] > 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_edit_data.loc[(all_users_edit_data['hp_enabled'] == 0) &\n",
    "                        (all_users_edit_data['num_article_edits'] > 0)].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write out the canonical edit dataset for importing into R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_edit_data.to_csv(edit_data_output_filename,\n",
    "                           header = True, index = False, sep = '\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
